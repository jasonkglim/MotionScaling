{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from utils import stratified_sample, annotate, even_train_split\n",
    "import glob  # Importing the glob module to find all the files matching a pattern\n",
    "\n",
    "# Pattern to match the data files\n",
    "file_pattern = \"data_files/user_*/metric_df.csv\"\n",
    "\n",
    "# Initialize a dictionary to store Dataframes for each dataset\n",
    "all_datasets = {}\n",
    "\n",
    "# Loop through each file that matches the file pattern\n",
    "for filepath in glob.glob(file_pattern):\n",
    "    # print(filepath)\n",
    "    # print(filepath.split('/'))\n",
    "    # user_name = filepath.split('/')[1]\n",
    "    user_name = filepath.split('\\\\')[1]\n",
    "    print(f\"Processing {filepath} dataset...\")\n",
    "\n",
    "    # Read in data file as a pandas dataframe\n",
    "    data = pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    # add weighted performance metric\n",
    "    w = 1\n",
    "    data[\"total_error\"] = data['avg_osd'] + data['avg_target_error']\n",
    "    data[\"weighted_performance\"] = 10*data['throughput'] - w*data[\"total_error\"]\n",
    "\n",
    "    all_datasets[user_name] = data\n",
    "\n",
    "# Combine datasets for Lizzie\n",
    "lizzie1 = all_datasets[\"user_lizzie1\"]\n",
    "lizzie2 = all_datasets[\"user_lizzie2\"]\n",
    "combined_df = pd.concat([lizzie1, lizzie2])\n",
    "all_datasets[\"user_lizzie\"] = combined_df.groupby(['latency', 'scale']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import PolyRegression, GPRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, RationalQuadratic, WhiteKernel\n",
    "import utils\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "## Choose model to apply, returning predictions over original dataset and dense inputs\n",
    "model_type = \"Poly2\"\n",
    "# model_type = \"GPR_RBF_default\"\n",
    "# model_type = \"GPR_RBF_anisotropic\"\n",
    "# model_type = \"GPR_RBF_Noise_default\"\n",
    "# model_type = \"GPR_RBF_Noise_anisotropic\"\n",
    "# model_type = \"GPR_RQ_default\"\n",
    "# model_type = \"GPR_RQ_Noise_default\"\n",
    "# model_type = \"blah\"\n",
    "\n",
    "# Configure logging to write to a file\n",
    "logging.basicConfig(filename='warnings_log.txt', level=logging.WARNING, format='%(message)s')\n",
    "\n",
    "# Function to redirect warnings to logging\n",
    "def warn_to_logging(message, category, filename, lineno, file=None, line=None):\n",
    "    logging.warning(f'{filename}:{lineno}: {category.__name__}: {message}')\n",
    "\n",
    "# Redirect all warnings to the warn_to_logging function\n",
    "warnings.showwarning = warn_to_logging\n",
    "\n",
    "all_results = {}\n",
    "output_metrics = [\"throughput\", \"avg_target_error\", \"avg_osd\", \"avg_movement_speed\", \"total_error\", \"weighted_performance\"]\n",
    "for output_metric in output_metrics:\n",
    "\t\n",
    "\tprint(output_metric)\n",
    "\tuser_results = {}\n",
    "\tfor user, data in list(all_datasets.items()): \n",
    "\t\t# if user == \"user_lizzie\" or user == \"user_lizzie1\":\n",
    "\t\t# \tcontinue\n",
    "\t\tprint(f\"\\t{user}\")\n",
    "\n",
    "\t\t# Prepare data \n",
    "\t\tX = data[['latency', 'scale']]\n",
    "\t\tY = data[output_metric]\n",
    "\n",
    "\t\t# Initialize evaluation metrics\n",
    "\t\toptimal_match_rate = []\n",
    "\t\toptimal_scale_error = []\n",
    "\t\tmse_scores = []\n",
    "\t\tfull_mse_scores = []\n",
    "\t\tn_train_mse = []\n",
    "\t\tn_train_full_mse = []\n",
    "\t\tn_train_p = []\n",
    "\n",
    "\t\tn = len(data)\n",
    "\t\tn_train_values = range(2, n-1)\n",
    "\t\tfor n_train in n_train_values:\n",
    "\n",
    "\t\t\tn_train_p.append(n_train / n)\n",
    "\t\t\t# Split into training/test sets\n",
    "\t\t\t# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=n_train/n)\n",
    "\t\t\ttrain_set, test_set = even_train_split(data, n_train)\n",
    "\t\t\tX_train, X_test = train_set[['latency', 'scale']], test_set[['latency', 'scale']]\n",
    "\t\t\tY_train, Y_test = train_set[output_metric], test_set[output_metric]\n",
    "\t\t\t\n",
    "\t\t\t# Create dense test input\n",
    "\t\t\t# latency_set = data['latency'].unique()# np.arange(0.0, 0.76, 0.01)\n",
    "\t\t\t# latency_range = np.array(data['latency'].unique()) #np.linspace(latency_set.min(), latency_set.max(), 50)\n",
    "\t\t\tlatency_range = np.arange(0.0, data['latency'].max()+0.01, 0.01)\n",
    "\t\t\tscale_range = np.arange(data['scale'].min(), data['scale'].max()+0.025, 0.025) #np.linspace(data['scale'].min(), data['scale'].max(), 50)\n",
    "\t\t\tlatency_grid, scale_grid = np.meshgrid(latency_range, scale_range)\n",
    "\t\t\tX_dense = np.c_[latency_grid.ravel(), scale_grid.ravel()]\n",
    "\t\t\tX_dense = np.round(X_dense, 3)\n",
    "\t\t\t\n",
    "\t\t\t# # Polynomial Regression\n",
    "\t\t\tif model_type.startswith(\"Poly\"):\n",
    "\t\t\t\tdegree = int(model_type.strip(\"Poly\"))\n",
    "\t\t\t\tY_pred, model_params = PolyRegression(X_train.values, Y_train.values, X.values, degree)\n",
    "\t\t\t\tY_pred_dense, _ = PolyRegression(X_train.values, Y_train.values, X_dense, degree)\n",
    "\n",
    "\t\t\t# Gaussian Process Regression\n",
    "\t\t\telif model_type.startswith(\"GPR\"):\n",
    "\t\t\t\t# Choose kernel\n",
    "\t\t\t\tkernel_type = model_type.removeprefix(\"GPR_\")\n",
    "\t\t\t\t# print(kernel_type)\n",
    "\t\t\t\tif kernel_type == \"RBF_Noise_default\":\n",
    "\t\t\t\t\tkernel = ConstantKernel() * RBF() + WhiteKernel() # Default RBF with likelihood noise\n",
    "\t\t\t\telif kernel_type == \"RBF_anisotropic\":\n",
    "\t\t\t\t\tkernel = ConstantKernel() * RBF([1.0, 1.0])\n",
    "\t\t\t\telif kernel_type == \"RBF_Noise_anisotropic\":\n",
    "\t\t\t\t\tkernel = ConstantKernel() * RBF([1.0, 1.0]) + WhiteKernel() # RBF with anistropic length scale\n",
    "\t\t\t\telif kernel_type == \"RQ_Noise_default\":\n",
    "\t\t\t\t\tkernel = ConstantKernel() * RationalQuadratic() + WhiteKernel() # Default Rational Quadratic with likelihood noise\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(\"Invalid kernel specification!\")\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t\tY_pred, Y_pred_std, model_params = GPRegression(X_train.values, Y_train.values, X.values, kernel)\n",
    "\t\t\t\tY_pred_dense, Y_pred_std, _ = GPRegression(X_train.values, Y_train.values, X_dense, kernel)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"Invalid model type specification!\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\t## Evaluate metrics\n",
    "\t\t\tdense_df = pd.DataFrame({\n",
    "\t\t\t\t\t'latency': X_dense[:, 0].flatten(),\n",
    "\t\t\t\t\t'scale': X_dense[:, 1].flatten(),\n",
    "\t\t\t\t\t'Y_pred_dense': Y_pred_dense.flatten()\n",
    "\t\t\t\t})\n",
    "\t\t\tdata[\"Y_pred\"] = Y_pred\n",
    "\n",
    "\t\t\t# Mean Square Error on whole dataset\n",
    "\t\t\tfull_mse = mean_squared_error(Y, Y_pred)\n",
    "\t\t\tif True: #full_mse < 5000:\n",
    "\t\t\t\tn_train_full_mse.append(n_train)\n",
    "\t\t\t\tfull_mse_scores.append(full_mse)\n",
    "\n",
    "\t\t\t# Mean Square Error on test set\n",
    "\t\t\tY_test_pred = data.loc[Y_test.index][\"Y_pred\"]\n",
    "\t\t\tmse = mean_squared_error(Y_test, Y_test_pred)\n",
    "\t\t\tif True: #mse < 5000:\n",
    "\t\t\t\tn_train_mse.append(n_train)\n",
    "\t\t\t\tmse_scores.append(mse)\n",
    "\t\t\t\n",
    "\t\t\tif output_metric in [\"throughput\", \"avg_movement_speed\", \"weighted_performance\"]: # optimal scale at maximum\n",
    "\t\t\t\toptimal_scale_dense = dense_df.loc[dense_df.groupby('latency')['Y_pred_dense'].idxmax()][['latency', 'scale']]\n",
    "\t\t\t\toptimal_scale_ref = data.loc[data.groupby('latency')[output_metric].idxmax()][['latency', 'scale']]\n",
    "\t\t\t\toptimal_scale_pred = data.loc[data.groupby('latency')['Y_pred'].idxmax()][['latency', 'scale']]\n",
    "\t\t\telse: # optimal scale at minimum\n",
    "\t\t\t\toptimal_scale_dense = dense_df.loc[dense_df.groupby('latency')['Y_pred_dense'].idxmin()][['latency', 'scale']]\n",
    "\t\t\t\toptimal_scale_ref = data.loc[data.groupby('latency')[output_metric].idxmin()][['latency', 'scale']]\n",
    "\t\t\t\toptimal_scale_pred = data.loc[data.groupby('latency')['Y_pred'].idxmin()][['latency', 'scale']]\n",
    "\n",
    "\t\t\t# Merge the results on 'latency'\n",
    "\t\t\tmerged_ref_pred = pd.merge(optimal_scale_ref, optimal_scale_pred, \n",
    "\t\t\t\t\t\t\t\ton='latency', suffixes=('_ref', '_pred'))\n",
    "\t\t\t\n",
    "\t\t\tmerged_ref_dense = pd.merge(optimal_scale_ref, optimal_scale_dense, \n",
    "\t\t\t\t\t\t\t\ton='latency', suffixes=('_ref', '_dense'))\n",
    "\t\t\t# print(optimal_scale_dense)\n",
    "\t\t\t# print(merged_ref_dense)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t# Count the number of matches\n",
    "\t\t\tmatches = (merged_ref_pred['scale_ref'] == merged_ref_pred['scale_pred']).sum()\n",
    "\t\t\tscale_error = np.abs(merged_ref_dense['scale_ref'] - merged_ref_dense['scale_dense']).mean()\n",
    "\n",
    "\t\t\toptimal_match_rate.append(matches / len(optimal_scale_ref))\n",
    "\t\t\toptimal_scale_error.append(scale_error)\n",
    "\n",
    "\t\t\t# Visualize model prediction\n",
    "\t\t\tif n_train == n-2:\n",
    "\t\t\t\tutils.model_heatmaps(data, dense_df, X_train, user, output_metric, model_type, model_params)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\t# Store results from this dataset\n",
    "\t\t\tuser_results[user] = {\n",
    "\t\t\t\t'n_train_mse': list(n_train_mse),\n",
    "\t\t\t\t'n_train_full_mse': list(n_train_full_mse),\n",
    "\t\t\t\t'full_mse_scores': full_mse_scores,\n",
    "\t\t\t\t'mse_scores': mse_scores,\n",
    "\t\t\t\t'n_train_all': list(n_train_values),\n",
    "\t\t\t\t'match_rate': optimal_match_rate,\n",
    "\t\t\t\t'scale_error': optimal_scale_error,\n",
    "\t\t\t\t'n_train_p': n_train_p\n",
    "\t\t\t}\n",
    "\t\t\tcontinue\n",
    "\t\tbreak\t\n",
    "\telse:\n",
    "\t\tall_results[output_metric] = user_results\n",
    "\t\tcontinue\n",
    "\tbreak\n",
    "\n",
    "# print(all_results.keys())\n",
    "with open(f\"model_result_data/{model_type}.json\", \"w\") as file:\n",
    "\tjson.dump(all_results, file)\n",
    "# with open(f\"model_result_data/{model_type}.json\", \"r\") as file:\n",
    "# \tog_results = json.load(file)\n",
    "\n",
    "# og_results[\"total_error\"] = all_results[\"total_error\"]\n",
    "\n",
    "# with open(f\"model_result_data/{model_type}.json\", \"w\") as file:\n",
    "# \tjson.dump(og_results, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting the results for all datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "## Choose model to apply, returning predictions over original dataset and dense inputs\n",
    "model_type = \"Poly2\"\n",
    "# model_type = \"GPR_RBF_default\"\n",
    "# model_type = \"GPR_RBF_anisotropic\"\n",
    "# model_type = \"GPR_RBF_Noise_default\"\n",
    "# model_type = \"GPR_RBF_Noise_anisotropic\"\n",
    "# model_type = \"GPR_RQ_default\"\n",
    "# model_type = \"GPR_RQ_Noise_default\"\n",
    "# model_type = \"blah\"\n",
    "\n",
    "with open(f\"model_result_data/{model_type}.json\", \"r\") as file:\n",
    "\tall_results = json.load(file)\n",
    "\n",
    "for output_metric, user_results in all_results.items():\n",
    "\n",
    "\tfig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "\tfig.suptitle(f\"Model Evaluation Metrics for {model_type} predicting {output_metric}\")\n",
    "\tfor user, results in user_results.items():\n",
    "\t\taxes[0, 0].plot(results['n_train_p'], results['match_rate'], marker='o', label=user)\n",
    "\t\taxes[0, 1].plot(results['n_train_p'], results['scale_error'], marker='o', label=user)\n",
    "\t\taxes[1, 0].plot(results['n_train_p'], results['full_mse_scores'], marker='o', label=user)\n",
    "\t\taxes[1, 1].plot(results['n_train_p'], results['mse_scores'], marker='o', label=user)\n",
    "\n",
    "\taxes[0, 0].set_title(\"Optimal Scale Prediction Rate\")\n",
    "\taxes[0, 0].set_xlabel(\"Training Set Proportion\")\n",
    "\taxes[0, 0].set_ylabel(\"Percentage of Correct Predictions\")\n",
    "\n",
    "\taxes[0, 1].set_title(\"Optimal Scale Prediction Error Using Dense Prediction\")\n",
    "\taxes[0, 1].set_xlabel(\"Training Set Proportion\")\n",
    "\taxes[0, 1].set_ylabel(\"Avg Error\")\n",
    "\n",
    "\n",
    "\taxes[1, 0].set_title('MSE on whole dataset')\n",
    "\taxes[1, 0].set_xlabel('Training Set Proportion')\n",
    "\taxes[1, 0].set_ylabel('Model Accuracy (MSE Score)')\n",
    "\n",
    "\taxes[1, 1].set_title('MSE on test set')\n",
    "\taxes[1, 1].set_xlabel('Training Set Proportion')\n",
    "\taxes[1, 1].set_ylabel('Model Accuracy (MSE Score)')\n",
    "\taxes[1, 0].legend()\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f\"figures/model_results/{output_metric}/{model_type}_model_eval_metrics_{output_metric}.png\", facecolor='w')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot averaged results\n",
    "\n",
    "# Load data\n",
    "## Choose model to apply, returning predictions over original dataset and dense inputs\n",
    "# model_type = \"Poly2\"\n",
    "# model_type = \"GPR_RBF_default\"\n",
    "# model_type = \"GPR_RBF_anisotropic\"\n",
    "model_type = \"GPR_RBF_Noise_default\"\n",
    "# model_type = \"GPR_RBF_Noise_anisotropic\"\n",
    "# model_type = \"GPR_RQ_default\"\n",
    "# model_type = \"GPR_RQ_Noise_default\"\n",
    "# model_type = \"blah\"\n",
    "\n",
    "with open(f\"model_result_data/{model_type}.json\", \"r\") as file:\n",
    "\tall_results = json.load(file)\n",
    "\n",
    "print(all_results)\n",
    "for output_metric, user_results in all_results.items():\n",
    "\tfig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "\tfig.suptitle(f\"Model Evaluation Metrics for {model_type} predicting {output_metric}, mean over users\")\n",
    "\n",
    "\t# Prepare lists of lists to store data\n",
    "\tmatch_rate_lists = []\n",
    "\tscale_error_lists = []\n",
    "\tfull_mse_score_lists = []\n",
    "\tmse_score_lists = []\n",
    "\tn_train_lists = []\n",
    "\n",
    "\t# Collect data for each metric\n",
    "\tfor user, results in user_results.items():\n",
    "\t\tmatch_rate_lists.append(results['match_rate'])\n",
    "\t\tscale_error_lists.append(results['scale_error'])\n",
    "\t\tfull_mse_score_lists.append(results['full_mse_scores'])\n",
    "\t\tmse_score_lists.append(results['mse_scores'])\n",
    "\t\tn_train_lists.append(results['n_train_all'])\n",
    "\n",
    "\t# Function to calculate average and standard deviation safely\n",
    "\tdef safe_mean_std(data_lists, index):\n",
    "\t\tvalid_data = [data[index] for data in data_lists if index < len(data)]\n",
    "\t\treturn np.mean(valid_data), np.std(valid_data)\n",
    "\n",
    "\t# Calculate averages and standard deviations safely\n",
    "\tavg_match_rate = []\n",
    "\tstd_match_rate = []\n",
    "\tavg_scale_error = []\n",
    "\tstd_scale_error = []\n",
    "\tavg_full_mse_scores = []\n",
    "\tstd_full_mse_scores = []\n",
    "\tavg_mse_scores = []\n",
    "\tstd_mse_scores = []\n",
    "\n",
    "\tmin_n_train_length = min([len(data_list) for data_list in n_train_lists])\n",
    "\tmin_n_train_list = n_train_lists[0][:min_n_train_length]\n",
    "\tfor n in range(min_n_train_length):\n",
    "\t\tmean, std = safe_mean_std(match_rate_lists, n)\n",
    "\t\tavg_match_rate.append(mean)\n",
    "\t\tstd_match_rate.append(std)\n",
    "\n",
    "\t\tmean, std = safe_mean_std(scale_error_lists, n)\n",
    "\t\tavg_scale_error.append(mean)\n",
    "\t\tstd_scale_error.append(std)\n",
    "\n",
    "\t\tmean, std = safe_mean_std(full_mse_score_lists, n)\n",
    "\t\tavg_full_mse_scores.append(mean)\n",
    "\t\tstd_full_mse_scores.append(std)\n",
    "\n",
    "\t\tmean, std = safe_mean_std(mse_score_lists, n)\n",
    "\t\tavg_mse_scores.append(mean)\n",
    "\t\tstd_mse_scores.append(std)\n",
    "\n",
    "\t# Plotting the average values and standard deviation\n",
    "\t# Plotting the average values and standard deviation\n",
    "\taxes[0, 0].plot(min_n_train_list, avg_match_rate, marker='o', label='Mean over users')\n",
    "\taxes[0, 0].fill_between(min_n_train_list, np.subtract(avg_match_rate, std_match_rate), \n",
    "\t\t\t\t\t\t\tnp.add(avg_match_rate, std_match_rate), alpha=0.2)\n",
    "\n",
    "\taxes[0, 1].plot(min_n_train_list, avg_scale_error, marker='o', label='Mean over users')\n",
    "\taxes[0, 1].fill_between(min_n_train_list, np.subtract(avg_scale_error, std_scale_error), \n",
    "\t\t\t\t\t\t\tnp.add(avg_scale_error, std_scale_error), alpha=0.2)\n",
    "\n",
    "\taxes[1, 0].plot(min_n_train_list, avg_full_mse_scores, marker='o', label='Mean over users')\n",
    "\taxes[1, 0].fill_between(min_n_train_list, np.subtract(avg_full_mse_scores, std_full_mse_scores), \n",
    "\t\t\t\t\t\t\tnp.add(avg_full_mse_scores, std_full_mse_scores), alpha=0.2)\n",
    "\n",
    "\taxes[1, 1].plot(min_n_train_list, avg_mse_scores, marker='o', label='Mean Over Users')\n",
    "\taxes[1, 1].fill_between(min_n_train_list, np.subtract(avg_mse_scores, std_mse_scores), \n",
    "\t\t\t\t\t\t\tnp.add(avg_mse_scores, std_mse_scores), alpha=0.2)\n",
    "\t\n",
    "\taxes[0, 0].set_title(\"Optimal Scale Prediction Rate\")\n",
    "\taxes[0, 0].set_xlabel(\"Training Set Proportion\")\n",
    "\taxes[0, 0].set_ylabel(\"Percentage of Correct Predictions\")\n",
    "\n",
    "\taxes[0, 1].set_title(\"Optimal Scale Prediction Error Using Dense Prediction\")\n",
    "\taxes[0, 1].set_xlabel(\"Training Set Proportion\")\n",
    "\taxes[0, 1].set_ylabel(\"Avg Error\")\n",
    "\n",
    "\n",
    "\taxes[1, 0].set_title('MSE on whole dataset')\n",
    "\taxes[1, 0].set_xlabel('Training Set Proportion')\n",
    "\taxes[1, 0].set_ylabel('Model Accuracy (MSE Score)')\n",
    "\n",
    "\taxes[1, 1].set_title('MSE on test set')\n",
    "\taxes[1, 1].set_xlabel('Training Set Proportion')\n",
    "\taxes[1, 1].set_ylabel('Model Accuracy (MSE Score)')\n",
    "\t# axes[1, 0].legend()\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f\"figures/model_results/{output_metric}/{model_type}_model_eval_metrics_{output_metric}_average.png\", facecolor='w')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot optimal scale\n",
    "\n",
    "\n",
    "output_metrics = [\"throughput\", \"avg_target_error\", \"avg_osd\", \"avg_movement_speed\", \"weighted_performance\"]\n",
    "for output_metric in output_metrics:\n",
    "\t# print(output_metric)\n",
    "\tuser_results = {}\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tfor user, data in list(all_datasets.items()):\n",
    "\n",
    "\t\tif user == \"user_lizzie\" or user == \"user_lizzie1\":\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tX = data[['latency', 'scale']]\n",
    "\t\tlatency_range = np.arange(0.0, data['latency'].max()+0.01, 0.01)\n",
    "\t\tscale_range = np.linspace(data['scale'].min(), data['scale'].max(), 50)\n",
    "\t\tlatency_grid, scale_grid = np.meshgrid(latency_range, scale_range)\n",
    "\t\tX_dense = np.c_[latency_grid.ravel(), scale_grid.ravel()]\n",
    "\t\tX_dense = np.round(X_dense, 3)\n",
    "\n",
    "\t\t## Choose model to apply, training on whole dataset, returning predictions over dense input\n",
    "\t\t# model_type = \"GPR_RBF_default\"\n",
    "\t\t# model_type = \"GPR_RQ_default\"\n",
    "\t\t# model_type = \"Poly2\"\n",
    "\t\t\n",
    "\t\t# # Polynomial Regression\n",
    "\t\t# degree = 2\n",
    "\t\t# Y_pred_dense = PolyRegression(X.values, Y.values, X_dense, degree)\n",
    "\n",
    "\t\t# Gaussian Process Regression\n",
    "\t\t# kernel = ConstantKernel() * RBF() # Default RBF\n",
    "\t\t# kernel = ConstantKernel() * RationalQuadratic() # Default Rational Quadratic\n",
    "\t\t# Y_pred_dense, Y_pred_std = GPRegression(X.values, Y.values, X_dense, kernel)\n",
    "\n",
    "\t\t# dense_df = pd.DataFrame({\n",
    "\t\t# \t\t\t'latency': X_dense[:, 0].flatten(),\n",
    "\t\t# \t\t\t'scale': X_dense[:, 1].flatten(),\n",
    "\t\t# \t\t\t'Y_pred_dense': Y_pred_dense.flatten()\n",
    "\t\t# \t\t})\t\t\n",
    "\n",
    "\t\tif output_metric in [\"throughput\", \"avg_movement_speed\", \"weighted_performance\"]: # optimal scale at maximum\n",
    "\t\t\t# optimal_scale_dense = dense_df.loc[dense_df.groupby('latency')['Y_pred_dense'].idxmax()][['latency', 'scale']]\n",
    "\t\t\toptimal_scale_ref = data.loc[data.groupby('latency')[output_metric].idxmax()][['latency', 'scale']]\n",
    "\t\telse: # optimal scale at minimum\n",
    "\t\t\t# optimal_scale_dense = dense_df.loc[dense_df.groupby('latency')['Y_pred_dense'].idxmin()][['latency', 'scale']]\n",
    "\t\t\toptimal_scale_ref = data.loc[data.groupby('latency')[output_metric].idxmin()][['latency', 'scale']]\n",
    "\n",
    "\t\t# print(optimal_scale_ref)\n",
    "\t\t# plt.title(f\"Optimal Scale by {output_metric}\")\n",
    "\t\tplt.xlabel(\"latency\")\n",
    "\t\tplt.ylabel(\"scaling factor\")\n",
    "\t\tplt.plot(optimal_scale_ref['latency'], optimal_scale_ref['scale'], marker='x', label=user)\n",
    "\tplt.legend()\n",
    "\tplt.savefig(f\"figures/optimal_scale_per_latency/{output_metric}.png\", facecolor='w')\n",
    "\tplt.show()\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot optimal scale per latency with model prediction\n",
    "\n",
    "output_metrics = [\"throughput\", \"avg_target_error\", \"avg_osd\", \"avg_movement_speed\", \"weighted_performance\"]\n",
    "for output_metric in output_metrics:\n",
    "\t# print(output_metric)\n",
    "\tuser_results = {}\n",
    "\tplt.figure(figsize=(12, 6))\n",
    "\tfor user, data in list(all_datasets.items())[:1]:\n",
    "\n",
    "\t\tif user == \"user_lizzie\" or user == \"user_lizzie1\":\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tX = data[['latency', 'scale']]\n",
    "\t\tlatency_range = np.arange(0.0, data['latency'].max()+0.01, 0.01)\n",
    "\t\tscale_range = np.linspace(data['scale'].min(), data['scale'].max(), 50)\n",
    "\t\tlatency_grid, scale_grid = np.meshgrid(latency_range, scale_range)\n",
    "\t\tX_dense = np.c_[latency_grid.ravel(), scale_grid.ravel()]\n",
    "\t\tX_dense = np.round(X_dense, 3)\n",
    "\n",
    "\t\t## Choose model to apply, training on whole dataset, returning predictions over dense input\n",
    "\t\t# model_type = \"GPR_RBF_default\"\n",
    "\t\tmodel_type = \"GPR_RQ_default\"\n",
    "\t\t# model_type = \"Poly2\"\n",
    "\t\t\n",
    "\t\t# # Polynomial Regression\n",
    "\t\t# degree = 2\n",
    "\t\t# Y_pred_dense = PolyRegression(X.values, Y.values, X_dense, degree)\n",
    "\n",
    "\t\t# Gaussian Process Regression\n",
    "\t\t# kernel = ConstantKernel() * RBF() # Default RBF\n",
    "\t\tkernel = ConstantKernel() * RationalQuadratic() # Default Rational Quadratic\n",
    "\t\tY_pred_dense, Y_pred_std = GPRegression(X.values, Y.values, X_dense, kernel)\n",
    "\n",
    "\t\tdense_df = pd.DataFrame({\n",
    "\t\t\t\t\t'latency': X_dense[:, 0].flatten(),\n",
    "\t\t\t\t\t'scale': X_dense[:, 1].flatten(),\n",
    "\t\t\t\t\t'Y_pred_dense': Y_pred_dense.flatten()\n",
    "\t\t\t\t})\t\t\n",
    "\t\t\n",
    "\n",
    "\t\tif output_metric in [\"throughput\", \"avg_movement_speed\", \"weighted_performance\"]: # optimal scale at maximum\n",
    "\t\t\toptimal_scale_dense = dense_df.loc[dense_df.groupby('latency')['Y_pred_dense'].idxmax()][['latency', 'scale']]\n",
    "\t\t\toptimal_scale_ref = data.loc[data.groupby('latency')[output_metric].idxmax()][['latency', 'scale']]\n",
    "\t\telse: # optimal scale at minimum\n",
    "\t\t\toptimal_scale_dense = dense_df.loc[dense_df.groupby('latency')['Y_pred_dense'].idxmin()][['latency', 'scale']]\n",
    "\t\t\toptimal_scale_ref = data.loc[data.groupby('latency')[output_metric].idxmin()][['latency', 'scale']]\n",
    "\n",
    "\t\t# print(optimal_scale_ref)\n",
    "\t\tplt.title(f\"Optimal Scale by {output_metric}\")\n",
    "\t\tplt.xlabel(\"latency\")\n",
    "\t\tplt.ylabel(\"scaling factor\")\n",
    "\t\tplt.scatter(optimal_scale_ref['latency'], optimal_scale_ref['scale'], marker='x', label=\"measured\")\n",
    "\t\tplt.plot(optimal_scale_dense['latency'], optimal_scale_dense['scale'], label=\"predicted\")\n",
    "\tplt.legend()\n",
    "\t# plt.savefig(f\"figures/optimal_scale_per_latency/{output_metric}.png\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot key metric heatmaps for average over users\n",
    "from utils import annotate_extrema\n",
    "\n",
    "delete_keys = [\"user_lizzie\", \"user_lizzie1\", \"user_lauren\", \"user_sarah1\"]\n",
    "sub_datasets = [all_datasets[key] for key in all_datasets.keys() if key not in delete_keys]\n",
    "\n",
    "combined_df = pd.concat(sub_datasets)\n",
    "averaged_df = combined_df.groupby([\"latency\", \"scale\"]).mean().reset_index()\n",
    "\n",
    "# averaged_df = all_datasets[\"user_lizzie\"]\n",
    "# Create a 2x5 subplot for the heatmaps\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "# Plot the heatmap for throughput\n",
    "heatmap_throughput = averaged_df.pivot(\n",
    "    index='latency', columns='scale', values='throughput')\n",
    "ax = sns.heatmap(heatmap_throughput, ax=axes[0], cmap=\"YlGnBu\", annot=True, fmt='.3g')\n",
    "axes[0].set_title('Throughput vs. Latency and Scale')\n",
    "annotate_extrema(heatmap_throughput.values, ax)\n",
    "\n",
    "# Plot heatmap for total error (target deviation + osd)\n",
    "averaged_df['total_error'] = averaged_df['avg_osd'] + averaged_df['avg_target_error']\n",
    "heatmap_error = averaged_df.pivot(\n",
    "    index='latency', columns='scale', values='total_error')\n",
    "ax = sns.heatmap(heatmap_error, ax=axes[1], cmap=\"YlGnBu\", annot=True, fmt='.3g')\n",
    "axes[1].set_title('Total Error vs. Latency and Scale')\n",
    "annotate_extrema(heatmap_error.values, ax, extrema_type='min')\n",
    "\n",
    "# Plot heatmap for combined performance (movement speed - total error)\n",
    "heatmap_combo = averaged_df.pivot(\n",
    "    index='latency', columns='scale', values='weighted_performance')\n",
    "ax = sns.heatmap(heatmap_combo, ax=axes[2], cmap=\"YlGnBu\", annot=True, fmt='.3g')\n",
    "axes[2].set_title('Combined Performance vs. Latency and Scale')\n",
    "annotate_extrema(heatmap_combo.values, ax, extrema_type='max')\n",
    "\n",
    "# plt.title(\"User A\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"{data_folder}/heatmap_key_metrics.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function, e.g., a sine wave function\n",
    "def smooth_2d_function(x, y):\n",
    "    return np.sin(np.sqrt(x**2 + y**2))\n",
    "\n",
    "# Generate sample points\n",
    "x = np.linspace(-5, 5, 10)\n",
    "y = np.linspace(-5, 5, 10)\n",
    "x, y = np.meshgrid(x, y)\n",
    "\n",
    "# Apply the function to the sample points\n",
    "z = smooth_2d_function(x, y)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'x': x.ravel(), 'y': y.ravel(), 'z': z.ravel()})\n",
    "\n",
    "X = df[['x', 'y']]\n",
    "Y = df['z']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
    "\n",
    "z_pred, _ = GPRegression(X_train, Y_train, X)\n",
    "z_pred = z_pred.reshape(x.shape)\n",
    "\n",
    "# df[\"y_pred\"] = Y_pred\n",
    "\n",
    "# Plotting the function for visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 8))\n",
    "\n",
    "ax = axes[0].contourf(x, y, z, cmap='viridis')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('y')\n",
    "axes[0].set_title('Smooth 2D Function')\n",
    "\n",
    "ax = axes[1].contourf(x, y, z_pred, cmap='viridis')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('y')\n",
    "axes[1].set_title('Predictions')\n",
    "\n",
    "fig.colorbar(ax, label='Function Value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataframes\n",
    "df1 = pd.DataFrame({'latency': [1, 2], 'scale': [3, 4], 'col1': [5, 6], 'col2': [7, 8]})\n",
    "df2 = pd.DataFrame({'latency': [1, 2], 'scale': [3, 4], 'col1': [9, 10], 'col2': [11, 12]})\n",
    "\n",
    "# Concatenating the dataframes\n",
    "combined_df = pd.concat([df1, df2])\n",
    "\n",
    "# Grouping by 'latency' and 'scale' and calculating the average of other columns\n",
    "grouped_df = combined_df.groupby(['latency', 'scale']).mean().reset_index()\n",
    "\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_samples_with_noise(x_min, x_max, num_x, num_samples, noise_std):\n",
    "    \"\"\"\n",
    "    Generates samples from a sine function with added Gaussian noise.\n",
    "\n",
    "    Parameters:\n",
    "    x_min (float): Minimum x value.\n",
    "    x_max (float): Maximum x value.\n",
    "    num_x (int): Number of distinct x values in the range.\n",
    "    num_samples (int): Number of samples to generate for each x value.\n",
    "    noise_std (float): Standard deviation of the Gaussian noise.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Generate x values\n",
    "    x_values = np.linspace(x_min, x_max, num_x)\n",
    "\n",
    "    # Plot the underlying sine function\n",
    "    plt.plot(x_values, np.sin(x_values), label='Underlying sine function', color='blue')\n",
    "\n",
    "    # Generate and plot samples with noise for each x value\n",
    "    all_samples = []\n",
    "    for x in x_values:\n",
    "        noisy_samples = np.sin(x) + np.random.normal(0, noise_std, num_samples)\n",
    "        plt.scatter([x]*num_samples, noisy_samples, color='red', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Samples from a Sine Function with Noise')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "generate_samples_with_noise(x_min=0, x_max=2*np.pi, num_x=30, num_samples=10, noise_std=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modeling approach 2. Using Bayesian Regression, and all users as prior\n",
    "\n",
    "# Separate datasets into one vs rest, compute weights for rest, use as prior for one\n",
    "# Two possible methods, compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100, 3)\n",
      "[ 1.         -4.8989899  24.00010203]\n",
      "(100,)\n",
      "[[1.00001983]\n",
      " [2.99991575]\n",
      " [2.00116591]]\n",
      "[[ 9.99988898e-05 -3.89789779e-26 -9.43257647e-09]\n",
      " [-3.89789779e-26  9.99905546e-05 -5.20263110e-24]\n",
      " [-9.43257647e-09 -5.20263110e-24  9.98556715e-05]]\n",
      "[[3.60295889e+01]\n",
      " [2.10190114e+01]\n",
      " [1.00107658e+01]\n",
      " [3.00485197e+00]\n",
      " [1.26998834e-03]\n",
      " [1.00001983e+00]\n",
      " [6.00110149e+00]\n",
      " [1.50045150e+01]\n",
      " [2.80102603e+01]\n",
      " [4.50183374e+01]]\n",
      "(10, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvQUlEQVR4nO3de3hU5bX48e8K11ABL6AikAQQ0Gg5tKY9R8FjFTiioNb2VPHgBbAGfxYeFS9VEAV8sNQWtWqtP4GqB6nUKoqgrYC/0loopdDiBRCQS7gUuVpCDSAk6/fHzMRJmEzmsvfsy6zP8+RJZjIz+509M2u/s971vltUFWOMMeFU4HUDjDHGuMeCvDHGhJgFeWOMCTEL8sYYE2IW5I0xJsSaet2AeO3atdOSkhKvm2GMMYGycuXKvaraPtH/fBXkS0pKWLFihdfNMMaYQBGRiob+Z+kaY4wJMQvyxhgTYhbkjTEmxCzIG2NMiFmQN8aYHKi/Tliu1g2zIG+MMS57fOF6Js1fUxvYVZVJ89fw+ML1rm/bgrwxxrhIVak8fJTnl2ypDfST5q/h+SVbqDx81PUeva/q5I0xJmxEhAcHlwLw/JItPL9kCwDD+5Tw4OBSRMTV7VtP3hhjXBYf6GNyEeDBgrwxxrgulqKJF5+jd5MFeWOMcVF8Dn54nxI2/+hyhvcpqZOjd5Pl5I0xxkUiQpuWzerk4GOpmzYtm7meshE/neO1rKxMbYEyY0wYqWqdgF7/cjZEZKWqliX6n6VrjDEmB+oH9FwMuoIFeWOMCTUL8sYYE2IW5I0xJsQsyBtjTIhZkDfGmBCzIG+MMSFmQd4YY0IsrSAvIr8Ukd0i8lHcdSeLyEIR2RD9fVL0ehGRJ0XkExH5QES+7nTjjTHGJJduT/4FYGC96+4D3lXV7sC70csAlwHdoz/lwC8yb2b2vDorizHGeCmtIK+qfwT217v6KuDF6N8vAt+Ou/5/NWIZcKKIdMiirRnz8qwsxhjjJSdy8qep6s7o358Cp0X/7ghsi7vd9uh1OeX1WVmMMcZLjq5CqaoqImlFTREpJ5LOoaioyMnmxB7f07OyGGOMl5zoye+KpWGiv3dHr98BdI67XafodXWo6nOqWqaqZe3bt3egOcfz8qwsxhjjJSeC/JvATdG/bwLmxl1/Y7TK5j+AA3FpnZzy8qwsxpjcs0KLL6VbQvky8Gegp4hsF5GbgSnAABHZAPSPXgZ4G9gEfAJMA25zrNVp8PqsLMaY3LJCi7rSysmr6nUN/Ktfgtsq8INMGuUkr8/KYozJnfhCC4ikZeM7eU6eqCMo8ubMUG6elcUY4x/x395jwl5oYWeGwruzshhjcssKLerKmyBvjMkPVmhRVyiCvI2kG2PACi0ScXQylBceX7ieysNHa7+OxV7kNi2bceeAHl43zxiTQ1ZocbxAB3kbSTfG1HfngB51PvuxQJ+vsSDQQT7TJQus0saYcHOq0CIMsSLwOfl0R9JtooQxJhVhiRWBD/LpjKTbipTGmFSEKVYEOl1TfyQ9PicPx/fobUVKY0wqwhQrAt2Tb2gkfXifkgZH0m2ihDEmFcliRZDKtgPdk4f0R9IbSu9YoDfGxGsoVrRp2ZTKw8cCU7Yd6J58TKoj6TZRwpjwcrJ3nSxWLFyzK1C5+sD35NNhEyWMCSenJ0UmixWtWzTl37ueEphcfV4FebCJEsaEjVuTIpPFClWts8plfAxJt7be7Vr8vAvyYCtSGhMmblbCJIoVycb1nli0Ia1vFLlYliUUOXljTH7Ltmou1Xx+slz9xHmrqTyUem19rmrx87Inb4wJl2yq5tLpTTc2rndH/+4gqX2jyFUtvvXk80SQ6nqNSUdjVXM1NTXH3T7+73R703cO6FEnCMeC9Z0DeqT9jSIX83ayDvIi0lNEVsX9VIrIHSIyQUR2xF1/uRMNNukLyxocxiSSbFLkmn9U8vBbaxt878ff9vklW+hy/9t1ZtAnC86JLqd7wpJcnOAk6yCvqutUtbeq9gbOA6qA16P/fjz2P1V9O9ttmfSFaQ0OYxqSqHc9ftDZlJ7RptH3vlO96XTn4eRq3o7TOfl+wEZVrbCKFX8I0xocxiRT/71cUFCQ0nvfqVnw6c7DydW8HXGyJycivwT+pqpPi8gEYBhQCawA7lLVzxLcpxwoBygqKjqvoqLCsfaYL6kqXe7/8svU5h9dbgHe5IVk7/1kixxm2hHyok5eRFaqalmi/zk28CoizYErgd9Er/oF0A3oDewEpia6n6o+p6plqlrWvn17p5pj4tiJjU2+auy9n8kih41Jdx6O2/N2nEzXXEakF78LIPYbQESmAfMd3JZJUbrLMRsTFqm+98M+C97JIH8d8HLsgoh0UNWd0YtXAx85uC2TIluvx+SrdN77YZ4F70hOXkS+AmwFuqrqgeh1M4mkahTYAoyMC/oJlZWV6YoVK7JujzleGM5VaUwm/Pjed7pNyXLyjvTkVfVz4JR6193gxGMbZ4S5p2JMMn577+divZp4NuPVGGOylM7aN7met2Jr1xhjTBbSXfsm1/NWrCdvjDEZyqRnnmiG7fhBZ7uWRrKevEP8OLhjjHFXJj3z+rX7VZ8sp+ScB/joL3+gTZs2jrcx1D35XK28aAuAGZO/0ln7Jr6nP+yCYsrbvM+eOQ+z67ODTJyz0pUYFdogn6vAawuAGZPf0plRHl+73+aTBYwbN44h117L3U/PplPHjq58+w9lusatcz4mYguAGZO/MplRHpthW1nZicLCQm699VbAvdJORxcoy5aTk6Hid36Mm4HXFgAzJj8lq665o3/3OnFgwYIFTJ06lTfeeIPCwkLH2pCTBcr8JhdnXIlxYgEwO3OTc2xfho+fX9OGzhQFX8YBVeVHP/oRAy+7jA/Wb2H//v05a19og3yuVl50YuF/G7h1ju3L8PHLa5rsQJOo8xhLGY99ZTnf/e53GTt2LIU9+jD8xy9xxhlnuN7emFAG+VydcQWyX6rUBm6dY/syfPzymqZ7oImPA08+OIbX35jLSZd8n3t+/AyTv1eW01RuaHPyuV4fIps6+VyPH4SZ7cvw8fo1zfTEItXV1RQUFNCp/DmqP99Py6Jero3VJcvJhzbIgzdnaMmUDdw6x/Zl+Hj9mqZzoDly5Ah33303+/bto8eQsbywtKLR+2QrLwdeIb3V57zM+9mZm5xj+zJ8/PCaplrIsXnzZvr27cvTTz/N5qpmPP+nTa6njBsT6iCfKi/zfrkcPwg725e5k6tqF7+8pqkcaN58802+/vWvs2HDBubMmcM1PxjHiAu7OXZawUyFcjJUuryc0GRnbnKO7cvcyOV4lx9e01QmPB08eJARI0bQrVs3XnnlFbp27Vp7X69PKxjqnHy6vMz72QJnzrF96Z5MByGd2K6Xr2lDB7aaf+3noWv7UFBQwKpVqzj77LNp0aJFztoV4/qZocKgoa9juTry+u3sNeD9BytTftyXYeHVt16vX9NEJ/s+q+ojym8tp+3OhxgzZgy9e/fOaZtS5VhOXkS2iMiHIrJKRFZErztZRBaKyIbo75Oc2p6T/JL38xO/TEAx/pPL2eR+Ent+n3/+ObfccgtDhgzh7LPP5uqrr/a4Zck5PfB6sar2jvvacB/wrqp2B96NXvadbCc0hY1fJqAYf/JDtYtXPvjgA8rKypgxYwb3338/7733Hl26dPG6WUm5na65CvhW9O8XgcXAD13eZkYSfR3Lh95JIql8JQ9K6sY4K5NVF8PkwIEDHDx4kIULF9KvXz+vm5MSJ3vyCiwQkZUiUh697jRV3Rn9+1PgtPp3EpFyEVkhIiv27NmTfSOyKO3yOu/nJ8lOUWapm/zlh2+9uV6sbOfOnTz//PMAXHjhhWzcuDEwAR4crK4RkY6qukNETgUWAqOBN1X1xLjbfKaqDebls62uyfVSBmGWaIZfaYfWzB/dl4ffWut6NYXxN68G5XP9GZ8zZw7l5eUcPnyYjRs3ctppx/VTfSEnM15VdUf0927gdeCbwC4R6RBtRAdgt1PbS7B9yyM7pP5X8k2PXEZph9as2XmQrmN/awHeePKt19XP+KxZUFICBQVQUkLltGkMHz6c7373u3Tp0oWVK1f6NsA3xpGevIh8BShQ1YPRvxcCk4B+wD5VnSIi9wEnq+q9DT1Otj15rxcyCpP6Paaamhq6jv1t7f9tPRjjBVc+47NmQXk5VFUBcBToJcJ6YNwDDzB+/HiaNWuWddvd5PoCZSLSlUjvHSKDub9S1ckicgrwClAEVADXqGqDq+U7MRnK64WMwiT2FdwOnsZPHP+Ml5RARQVfAM2jV80Ezjz9dM7fubPh+/mI6+kaVd2kqv8W/TlHVSdHr9+nqv1Utbuq9k8W4B1qR96WdrmhfoC3OQTGa658xrdu5c/AV4FfR6+6ATh/167MH9NHQrNAmZ+CUa5H/93kh2oKY8Cdz/jhw4e5t3Vr+gKHgVPj/1lU5FDLvRWaZQ38sJARhLPCx+YQGD9w+jO+bNkyhg8fzseVlZQ3bcpPjh2jTeyfrVrB5MnOPgGPhCbIg/fBKH70Hzhu8aYgTyCyOQTGD5z8jG/bto2qqireeecd/mvPHhg3DrZujfTgJ0+GoUOdbr4nbBVKh9kgZeqCugBaPgnba7Ro0SIqKiq4+eabUVUOHTpEq1atvG5W1nJSJ28i8nXxpnTZAmj+F6bXaP/+/QwfPpwBAwbw1FNPUV1djYiEIsA3xoK8w6zCp3GJJrVMnLe6zqQW21/eCsvkQlVl1qxZnHXWWbz00kuMHTuWZcuW0aRJE6+bljPhyMnPmuWLfFq+L96UqoYWQBt2QXHt9UEfrA46r9aNd9qaNWu44YYb+MY3vsHChQvp1atXqNJPqQh+Tz42W62iAlQjv8vLI9e7IFl5pB/KDYNSvpkorSVE9k8Qe4xhFNTU45EjR5g/fz4A55xzDr///e9ZunQp/293YUrpp6B8hlIV/CA/bhxUVbEDqE2SVFVFrndYKjnKOwf0qPNBiH1QctEjDVIONVFa6/mlW+hy/9u2No5PBDH1uGjRInr16sWVV17J+vWR9/1FF11EQUFBSumnIH2GUhX8IL91KwAPAP8G3AscjLveKenkKEO3eJPDEk1qGXZBcZ3bWID3VqYTj7zqBW/bto1rrrmGAQMGUFNTw+9+9zt69PiyYxX/rfr5JYk7E0H6DKUj+Dn5oiKoqOBRoAnwE+BXwE9POYVrHcy3+T1H6ff2xauf1oIvUzUxuTy/rjleJhOPvJoIePjwYcrKyqisrGTSpEncc889tGzZMuFzenBwaZ3y5kTfusH/n6F0BL8nP3kytGpFe2A6sBQ4TYTr9u7l0UcfdXRTfs9R+r198WJpLYjm4JduYfgFtjaOn6STesx1L1hV+eMf/4iq0rJlS5599lnWrl3L+PHjEwb42H0aSz8F6TOUquAH+aFD4bnnoLgYRDi/uJjlL77ItOh60ADr169n9+7sl7J3Ikfp5tfZoOVQRaRuj/EKWxvHb1JNPaaSDmlMqp+NtWvXMmjQIC666CLmzZsHwNVXX01JSUnSx04l/RS0z1BKYjXJfvg577zz1A0XXnihtmnTRn/yk5/o4cOHM3qMmpoanfDmR1r8w/k64c2PEl5uzGML1tW5bewxHluwLqM2xbetTnvmZtY+L9Vvn9/baxKrqanR4h/Or/1J9XVM5bOxd+9eHTVqlDZp0kTbtm2rjz32mH7xxRcpt62xbTjxGfcKsEIbiKvB78mn4LnnnuPCCy/knnvuobS0lN/85jdpH5mzLY9Ul77OxqoBIJIrHX5BCYryxKINgeoR29o4wRd7T8dLpRecymdDVenXrx/PPPMMI0eOZMOGDdx5551pncyjsfSTH0qgXdFQ9Pfix62efMw777yjX/3qVxXQF154IaPHyKbHGd8ziP1k00NI1NN4aO6HdS77ufdhwiPbXnDs9qMH36Xb2rTXakT3tztdX7v99tpv34sWLdIPP/wwJ88l2WU/IklPPu8WKKuuruZXv/oV3/ve92jZsiWLFy/m9NNP56yzznJ1uzGqzp7VRtUWRDOZUXV28bFsq2t01iwODbuZVseOsJhIOfRfgWk338z3p0/PuF35wPXT/zkl16tQqiq9evVi7dq1jBgxggcffJBOnTqldf90PiSNBeRMP2ROHzhM+LlV7pjpgUNVOXBaR7bs2clY4LdAJyInir6xqIgmFRUZtykfuLoKpYh0FpHfi8gaEVktIrdHr58gIjtEZFX05/Jst+U0EeHdd9/ltttu44UXXqB79+7cc8897Nu3r9H7pjszLj7AD+9Twu39zqS0Q+vaPGRNTU1GM+tijxsv8NUAxlXq0vgQZDa2UnuA2fMptwF/Bh4F1gPDgYJt2zJuj3GmhPIYcJeqlgL/AfxARGKFpo+rau/oz9sNP4R3Tj31VJ588knWrVvHNddcw9SpU1m8eHHS+2TyIYkf1Bk/6GwqDx9jzc6DlHZoTesWTXn4rbVpf8jqHzisxjwz9fdT2PebE+WOTqmoqOC2225DDlVS2f50XgQ2A/cAhbH2huQ0fF5xPF0jInOBp4E+wL9U9aep3tcPJw1Zt24d3bt3p6CggMcff5yqqipGjx5NmzZt6twu01x47OurU7n0MJ5uMJfyef95mebbvn07jzzyCNOnT0dEmD17Nt+uqkLKyyNrT8W0ahWZBxOSszS5JWcnDRGREuBrwF+iV40SkQ9E5JciclID9ykXkRUismLPnj1ONicjPXv2pKAgsltWrlzJAw88QJcuXXjkkUeorKysvV2mM+MSTaFOdv/GepleLogWdG6mLfzOqzRfTU0No0ePplu3bkyfPp2bb76ZjRs3cvXVVyP1JjZSXGwB3gkNld2k+wOcAKwEvhO9fBqR5WQKgMnALxt7DLdLKNMRK5tavny5Dh48WAE96aSTdPbs2bWlia+OmVJb7rWtTXt9dcyUhOVWiUqyUimndGvylPmS02WtQZBpuWM2pYW7d++u/Xvo0KFaXl6umzdvzqj95ngkKaF0ZIEyEWkGvAbMUtU50YPHrrj/TwPmO7GtXIj/Cv+nf7al7JYpdPjW9fz5tWkUFRUxcd5q9KVfctOcn9Op+gsAOlXu4eQnH2IO8J2f3lvbs06UDpg4bzWrth1g1bZ/NnhyESC0JwX3k8YWrQqjXC4+tnbtWqZMmcLLL7/MqlWrKC0tZebMmaHev36TdZCXyKs1A1irqo/FXd9BVXdGL14NfJTttnJB477CqyqC8PzSLcAJDLvvCRbsEV5YuoW+c5+ltPoLRgB3A12BVseOMOClJ5GpPzzuseDLQP3C0gp6d27L8AuSf8jCuCKe38SCVbx8WAHzzgE96nQUYu/BRM+5ofdxsg7HX/7yF6ZMmcIbb7xBYWEho0aN4pRTTqndlsmdrAdeRaQv8B7wIVATvXoscB3QG1BgCzAyLugn5IeBV0g8qBpveJ8Shlx5Lj8FXgSqgf8mUhFQJgI1NUkfq84Su43UFKvVwLsm/rWp/43KDqZ1JXsf199HBw4coEOHDrRs2ZJRo0YxevRo2rdvn+MW5xdXB15V9U+qKqraS+PKJVX1BlX9avT6KxsL8H6SaFA03oODS+lZXMw0IuVedwG/I/J1hqIiVJWaaKBPNsDaWE1xQ73MbA/MJiK0a5W4INn7+NChQ0yfPp3rr78eVaVt27a89dZbbN26lUmTJiUN8PXfy/bedl5eLFCWrkTBNd6k+WvQ6Dr2HYlM3NgGTCoshMmTWbJkCWeddRY///nPOXjwYMaLNlkNvPtyVZ0UpGCWqK2JPhP3/O8feOCBBygqKuKWW25hzZo1fPbZZwBcfPHFnHDCCUm3E8ZT7fmRBfl64oPrsAuKGX5BSe3/YpefX7KFSW16o3HlXm2Ki2k/bVptudfJJ5/MqFGjaH/6GUydOJYru0hagdp6mbnj9gqYuQ5m2RxQErV14rzVXP3M0jodjotO2MXUEf2Z/Mgj9OnTh8WLF7Ny5UpOPvnklNuYr+WruRb80/85rH5wfWLRhtrle9sWNueO/t1BogOkVwxNWMPbt29fli1bxrJly/jB2Mms+uPb/PrBZTx2845GqxjipTM45pX64whW9VNXJoOW2chmcld8W89dPJ/vvPoMbNvG91u3438Hj6DmpEJ6fn4QkXN45s5r2fj3JfznFUN4ZNiAtNsZn/6xwgJ35fUCZcnEf/hi+yj+cjpvwn/84x+sXbuWfv36UV1dTb9+/bjkkksYMWJEWgui+U2+zhZN98CW7eB7Ou3KdiBZVZlz96Nc9uRDtDp2hA+BaUQKDCqJnIFpzpw5Wbc1fntWWJC9nM14DZP4N1r9QdJ034RnnHEG/fr1A2Dfvn00b96chx56iOLiYq688krefPNNjh496kzDcyRfv25nknppaNDyiUUbHE3jOLEmjYjwnVefodWxI9wO9AL+LzAY+NNpp/Haa6/VuW02rLAgNyzI59ipp57KggUL2LhxI/fddx9//etfueqqq1iwYAEQWe8+CPy0yFWuZHpgSxTMJs5bTeUh5w+SmS63oaq89957DB8+nB1btwJwOfAYsAOYBfTZvdux19UKC3LH0jUeO3r0KO+88w4DBw6kadOmjBs3jgULFnDTTTcxZMgQ2rVr53UTk8q3r9vp1IvXv339FMqwC4rjJts1/lhutG/jxo3MnDmTmTNnsmnTJpoXtmIaTbnxUOVxt9WiIsTBdd29TveFaTzJ0jU+1qxZMwYPHkzTppEx8B49enDs2DFGjx5Nhw4dGDx4MK+++mrdO82aBSUlUFAQ+T1rVs7bDfn5dTvdnnKyKqm2hc158Ir0e90NSbV3HPu2uG/fPnr27MmkSZPo2rUrL774IhNnL+Er/2cs2qpVncc+2qIl8sgjGbWrIV4urpdP5ZsW5H3mpptu4u9//zvvv/8+Y8aM4f333+c3v/lN7f8X3Hcfh265BSoqQDXyu7w854E+X79uZ3JgayiY3dG/u6MHyWQHlCZf/IsZM2YwYMAABg8eDMApp5zCzJkz2bp1KwsXLuTGG2/kvit7R9ZeiisP1qIims2Y7spqkG6XryaSd+NJ9Vcs8/LHT6tQ+kV1dbXu379fVVXXrVungH4F9BrQV0D/FQn1qsXFOWtTbPXB2CqZ1dXVtdeHeZXMbE9W7dZjJXrsmLlz5+qAAQO0adOmCmi3bt10/Pjxnq6y6YcTZYdt9VHcXoXSOEvjcoMFBQWceOKJAHTt2pWFwKvAHOAVoCXwFnDJ1q0Z5RTr36exx4jPo945oAc1NTU8/Nba2jxqWAddIbPVG3PxWPE2bNjA3LlzueWWW2jbti3r169n8+bN3HXXXVxzzTV87Wtf8/T18ToPH5NPq49akPeZxj4E/YuL6V9Rwc+JrAr3OpFV4Cgq4sknn+Tll19m8ODBDBo0iN69e6ccsFP5wGmCiT2x0xamOrEn3YOK3zgxQS12/9hjxWTyWEePHmXJkiXMnz+ft956i48//hiAs88+m0GDBnH77bdz1113+WIfJ3r/eLV8duy9Hi+sq49aTt5H4j8EDeYKo2vmNAG+BfwMOLlVK5g8mXbt2qGqjB8/nq9//eucccYZ3HLLLQlzjCltq55syybDMtiVTR65/j4A6uyDOo/VwAD75s2b2bBhAwCbNm3i4osv5qmnnqKoqIif/exnbN68mUGDBgGRgX2/BC2/lN3Gv9fzYTzJevI+ktJU79jg17hxsHUrFBVFAv/QoQwFhg4dyqeffso777zD7373O/bs2VP74Rk5ciRt27bl4osvpm/fvhlNK8/0a66fenFeSWsfzJoVGVCvqmI38IeKCt4dNoxFY8awcfdurr/+embOnEmPHj2YP38+F110UaMLgvmBH9IkbqXK/Mrq5H1IXag9r6mpYeDAgSxevJijR4/SpEkTvvGNbzBy5EgmfPzlUrCNbSu+FxSTzpR5J05eHmSp7IPt27ezsayMi3ZFTq5WCqwFWgPfKixkwI9/zKWXXkqPHsFbOsJP74Ggpw7jWZ18gDSUK8z2YFxQUMCCBQv45z//ycKFC/nhD39IQUEBs/+0FoDqqgP8Y8ZtlA38HjNmzGD16tXHzb5VjaxrcvP1F7P50SvY/PJtTD36UcpfczOdjRlU9fdHLIjU3wff6yY89dRTXHfddZSUlNC5c2eu3rWr9gw8jwPLgH3Am4cPM3r06MAHeD+kSbwo3/SCpWt8pP6HING5X7N9I7Zq1Yr+/fvTr1+/Otv6n7OaM+jPxaz64zt8f0FkfZITTjiB2bNnM2jQIPbv38/uGTMY9PRDtPziSOTBtm7lO89OglsfZGvL7in35OOFdbAr0aD2g6+v4vOdm/nk4w/Zt2Q5J108goJmLRn54GP86bUZdOrUifPPP58777yTC6dMgU8/BeDS+AcuKvLk+WQiUc84n9IkfmFB3kdymStMtK11y//AhDc/4sje7ZQ228Py5ctre4zz5s1j2L33UgicC/xb9PeNVVV859Vnas9r25BcHMBcM2tWwjGQhlRXV7NlyyZeX3MQgP9ovp0bR45m97ZNUBP5dtS88Cu89eIU5mwpYNrBC7nzl9cxddglX+6Ddu1qc/K1ogPsQZCscivRxDDfvvYh4HpOXkQGEikCaQJMV9UpDd3WcvIRucwVprqtbdu28W5REe8DHwDvE0kf7AJOFeHxqVOZPXs2PXv2pHv37px55pl069aNsrIyCgoiWcGsaqTTDLSOiRsArdWqFTXPPsuxa6+lefPm7Nixg1/84hesW7eO9evXs2HDBg4dOsQ19z3OX7Q7R/6xjgNLZ3Ne7150Petc2nbuyePf/y+aNGmSfB949ZyzlOyAnm9jMLmSLCfvapAXkSbAemAAsB34K3CdqiY8t54XQT5Mgy9OSLo/SkoiyygQOTv7LuA0QIqLeXHiRGbOnMm6devYvn07AC1atKCqqoqCggImTJjA8uXL6dixI506daJjx44UFRUxYMAARITq6mqaNGmSuFENBFqee86VoFdVVcXu3btp0aIFHc4/n8qKCh4l8gbeBlREfz/6xBPcfvvtrF+/ntLSUrp27UrPnj3p0aMHpaWl9O/fn4t+8VHt48YGtf14EHdju34ZYM0HyYK82+mabwKfqOqmaENmA1cBDZ9ANYf8MvvOLxrdH5Mn1wZbAU6H2hTCTUOHctNNNwFw6NAhNm3axM6dO2t78QC7d+/mb3/7G7uiVSPdunXjk08+AeDSSy9l+fLltGvXjpNOOokTTzyR3r17M3XqVBg3jmerqtgHFEZ/WlRV0XnMGAZEg/yCBQs4dOgQqpGTqKsqHTp04IILLgBg+vTpHDhwgKqqKj7//HP+9a9/UVZWxrBhw6ipqeG8885j37597N27l0OHDgEwZswYpm7dSlNgCtAB6ASUAd8FzjvvPADOPPNMDh06RLNmzWqfazrjD24FPS/f342VSuZ7ZyqX3A7yHYl0emK2A/8efwMRKQfKAYpyOKhkddt1pbQ/ktToxyssLOScc87hnHPOqb1uwoQJTJgwAYAjR46wc+dOPv/889r/DxkyhHPPPZd9+/bx2Wef8dlnn9UeDNi6lWeAD+u1ecDu3cROPDdy5Ei2bNlS5//f/va3ef311wG4//772bt3LxCZINS6dWuaNGnCsGHDKCgooEePHhQWFtK+fXvatWtHu3btIkH8tddoVVHBESL5xlrFxdC3LxCpXIo/mLk5/pBqz9zr93eig9zEeat56IrIeyKfO1O55na65r+Bgar6/ejlG4B/V9VRiW6f63SNfaWsy7f7o6QErajgKHAIqAKOAk07duSMaGpozZo1HD58mIKCAkQiZ/I66aST6Ny5MwB79+6lefPmFBYW1ulxNyrDVJEbvehMlqHw4vWM3279NfPjL/vivRUSXqZrdgCd4y53il7nC36Yfecnvt0fkycj5eU0r6qiOdAWIoH2xz+uvUlpaWlD9wbI6OQr9b+96NatSIoDoNmucVO/p11TU5N2z9yr17N+5VbM80u38MLSyJiOBfjccXsy1F+B7iLSRUSaA0OAN13eZsrcmngUVL7dH0OHRnrO0fXNKS52bdA1ps4aM0OHops3M2nuhzw+bUHK2800955ojZ+H31pL6xZN01r3xcvXM35FUhFJ++QoiSaSmcy4GuRV9RgwCniHyMzsV1R1tZvbTJXfZt95zff7Y+hQ2LIFamoiv10M8Jks3paLbR88cozxg86uc/tUTzvoxesZP8iazsEmLAvZ+YXrk6FU9W3g7UZvmGP5tkhRY2x/fCmlheI82Pb4QWfz8Ftr69w+WcWOH17PdAehvR4wDqO8X6DM6uTrcmN/ZPOYXr4+biwUl+m2Nz1yWZ21+1OdYOSH93dQBoyDzMuBV9/Ll0WKUuX0/simysTLOm8v19lJtO3I2beapt0z98P7O91BaN8WAASUrUJpXJNNbtvrvLhX+exk2648HMnJ1w+WQag1T+dg49sCgIDK+568cU+mue36S/J6kRf3Kp/d2LbjJ13Fbh8mmeTwvU5H+V3e5+SN+9LJbddP0dTU1NB17G9Tuq/TvB4PyNfglWqazpYl+VKynLyla4yr0vnqXT9FU1NTw+Cn/pTSfVNtS7LL9aWSYnCrnrux3qrT/FSXHl9jD4nTUl6m84LG0jUBErTeXbpfvRtK0ZR2aM380X1rq0sS3bcxflhmoDGJXt8nFm1wvbfqxx5xYwdYL9N5QWM9+YDIZIKI172zhvLLw/uUNJjbjv/wxswf3ZeCgoJG75uIqtbt9c1zptfndE8y0es7cd5q/rB+j6u91SD3iBO9VyzAH8968gGQyQQRv/TO0i2fa6h8MP4gkc7yALF98ODgUtDI+imxxbKy6fU52ZNs6PV9YWkFwy4o5mudT0y4jUSPk+5zCXKP2Msy1yCxIB8A6X4Q/TZrMNXyuXTTO8kk2gdK3V5ptsHAqXruxl5foPbAFNuGk2mcINalO/leCTtL1wREOl9N49MiqS5m5QeZpHeSPVb9fRBbATEm29prJ+u5G3p9Y48Zb+K81VQeci7Fku3z8CIt6OR7JeyshDIgMpnq7eW0/Gw4OcBcfx8Mv6CEB6/I/pyjyXqSmaZs6r++idZeb2iddsg8VZTN8/A6LRi0YgS32LIGAZfJV9Mg5yudmoqfaB/EUjbZTm5ycsJUste3d+e2kQNTgm3c0b/7cWmcTFJFmT4PP6QF/bBsg99ZTz4g0ukxOd3LDKJE+2DivNW8sLSiTq472/3gVE8y2et7R//uCevknVzEK9PnYYuJ+UOynrwF+QBJ54Po9ddoPwjaPkj19fXbQTyoacEwsSCfpyxfGd594JcDmPXk/cFy8nnK8pXh3QfZnkPWCVbGGAwW5I1jwtpr9iuvD2BODj4b92SVrhGRnwBXAF8AG4HhqvpPESkhck7XddGbLlPVWxt7PEvXBJdf0gdusQNYw2zfeC9ZuibbyVALgXNVtRewHrg/7n8bVbV39KfRAG+CK8jrn6TCTiydnNffKExyWaVrVHVB3MVlwH9n1xwTREFe/6QxfqgFNyYbjlXXiMg84Neq+lI0XbOaSO++EnhAVd9r4H7lQDlAUVHReRUVFYluZgIgrKV0VkFi/C6rdI2ILBKRjxL8XBV3m3HAMWBW9KqdQJGqfg0YA/xKRNokenxVfU5Vy1S1rH379uk+N+MTTq7j4jfprBtkjN80GuRVtb+qnpvgZy6AiAwDBgNDNfqJVtUjqrov+vdKIoOywR99MwnVL6XL5YmvcyHMBzATflnl5EVkIHAvcJGqVsVd3x7Yr6rVItIV6A5syqqlxrfCXEpnteAm6LKtk38aaAEsjL7RY6WS/wlMEpGjQA1wq6ruz3JbxsdyNTkn1+V6YT6AmfxgyxqYwPCyFj+Vg4vVixuvuFknb0xOeF2L31gtuNXSG7+yZQ1MIPi5Ft9q6Y2fWZA3gREL9H47F6mfD0DGWLrGBIafSxmtlt74lQX5PFQ/KPohSDbG6Vp8p/eBnw9AMUF83U32LMjnmaAOEDZUyji8T0napYxO74MgTAYL6utusmc5+TwS9AFCJ2rx3dgHfq+lD/rrbrJjdfJ5xhbbcm8f+LlO3l73cLM6eVPLBgjd2wd+XlfdXvf8ZUE+zwRhgNBt+bgP8vE5mwgL8nkkCAOE6cikWiRs+yAm2b4I63M2qbGB1zzi9wHCdGS6jk2Y9kFMY/sijM/ZpM6CfJ7J1WqRbsq2WiQM+yAm1X0Rpuds0mNBPg/5eYAwFU4sIxD0fRCTzr4Iy3M26bGcvAkkqxb5ku0Lk4wFeRNIblWLBHHqv1XOmGQsyJvAcataJIhT/61yxjTGcvImcNyoFgnq1H+rnDGNsWUNTGA5vYxAkKf++3lJBeM+15Y1EJEJIrJDRFZFfy6P+9/9IvKJiKwTkUuz2Y4xiSQLapl0XoI8gGmVM6YhTuTkH1fV3tGftwFEpBQYApwDDASeEZEmDmzLmOM4lUu3AUwTRm4NvF4FzFbVI6q6GfgE+KZL2zJ5zKkTfNsApgkrJwZeR4nIjcAK4C5V/QzoCCyLu8326HXHEZFyoBygqKjIgeaYfOLU+VVtANOEVaMDryKyCDg9wb/GEQnkewEFHgY6qOoIEXkaWKaqL0UfYwbwW1V9Ndm2bODVZEpV6XL/27WXN//o8oyrbGwA0wRNsoHXRnvyqto/xY1MA+ZHL+4AOsf9u1P0OmMc11AuPZNBUxvANGGTbXVNh7iLVwMfRf9+ExgiIi1EpAvQHViezbaMScRy6cYkl21O/lER6U0kXbMFGAmgqqtF5BVgDXAM+IGqVme5LRMguUp7WC7dmORsMpRxXKZrvWfDcukmn9k5Xk3OOFXSmC7LpRuTmK1dYxzlVEmjMcYZ1pM3jgvy8gDGhI0FeeM4Wx7AGP+wIG8cZSWNxviL5eSNo6yk0Rh/sRJK4woraTQmd6yE0uSclTQa4w8W5AMqiCecNsbkngX5AAriCaeNMd6wIB8wXs0oNcYEk1XXBIzNKDXGpMN68gFkM0qNMamyIB9ANqPUGJMqC/IBYzNKjTHpsJx8wNiMUmNMOmzGa0DZjFJjTIzNeA0hm1FqjElFVukaEfk10DN68UTgn6raW0RKgLXAuuj/lqnqrdlsyxhjTPqyCvKqem3sbxGZChyI+/dGVe2dzeMbY4zJjiMDrxLJFVwDXOLE4xljjHGGUzn5C4Fdqroh7rouIvJ3EfmDiFzY0B1FpFxEVojIij179jjUHGOMMZBCdY2ILAJOT/Cvcao6N3qbXwCfqOrU6OUWwAmquk9EzgPeAM5R1cpGtrUHqEj7WXivHbDX60bkmD3n/JBvzzmoz7dYVdsn+kfWJZQi0hTYAZynqtsbuM1i4G5VDWV9pIisaKh8KazsOeeHfHvOYXy+TqRr+gMfxwd4EWkvIk2if3cFugObHNiWMcaYNDgx8DoEeLnedf8JTBKRo0ANcKuq7ndgW8YYY9KQdZBX1WEJrnsNeC3bxw6Q57xugAfsOeeHfHvOoXu+vlrWwBhjjLNsWQNjjAkxC/LGGBNiFuQdJiJ3iYiKSDuv2+I2EfmJiHwsIh+IyOsicqLXbXKDiAwUkXUi8omI3Od1e9wmIp1F5PciskZEVovI7V63KVdEpEl0Eud8r9viFAvyDhKRzsB/AVu9bkuOLATOVdVewHrgfo/b47hoKfDPgcuAUuA6ESlNfq/AOwbcpaqlwH8AP8iD5xxzO5HFFUPDgryzHgfuBfJiNFtVF6jqsejFZUAnL9vjkm8Smc29SVW/AGYDV3ncJlep6k5V/Vv074NEgl5Hb1vlPhHpBAwCpnvdFidZkHeIiFwF7FDV971ui0dGAL/1uhEu6Ahsi7u8nTwIeDHRZcO/BvzF46bkwhNEOmk1HrfDUXb6vzQkW8cHGEskVRMqKa5dNI7IV/xZuWybcZeInEBkvssdja07FXQiMhjYraorReRbHjfHURbk06Cq/RNdLyJfBboA70fP0NQJ+JuIfFNVP81hEx3X0HOOEZFhwGCgn4Zz0sUOoHPc5U7R60JNRJoRCfCzVHWO1+3JgT7AlSJyOdASaCMiL6nq9R63K2s2GcoFIrIFKFPVIK5mlzIRGQg8BlykqqFcJzq6AN96oB+R4P5X4H9UdbWnDXNR9PwQLwL7VfUOj5uTc9Ge/N2qOtjjpjjCcvImG08DrYGFIrJKRJ71ukFOiw4sjwLeITIA+UqYA3xUH+AG4JLo67oq2sM1AWQ9eWOMCTHryRtjTIhZkDfGmBCzIG+MMSFmQd4YY0LMgrwxxoSYBXljjAkxC/LGGBNi/x+d2bGhxJHcCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "## Bayesian Linear Regression\n",
    "class BayesRegression:\n",
    "\tdef __init__(self, train_input, train_output, noise=0):\n",
    "\t\tself.X = np.array(train_input)\n",
    "\t\tself.y = np.array(train_output).reshape((-1, 1))\n",
    "\t\tself.input_dim = self.X.shape[0]\n",
    "\t\tself.num_examples = self.X.shape[1]\n",
    "\t\tself.prior_mean = np.zeros((self.input_dim, 1))\n",
    "\t\tself.prior_covar = np.identity(self.input_dim)\n",
    "\t\tself.noise = noise # Defines the variance of gaussian observation noise\n",
    "\n",
    "\t# Define custom prior for weights\n",
    "\tdef set_prior(self, mean, var):\n",
    "\t\tself.prior_mean = mean.reshape(-1, 1)\n",
    "\t\tself.prior_covar = np.identity(self.input_dim) * var\n",
    "\n",
    "\t# Computes poseterior parameters from training data and prior \n",
    "\tdef fit(self):\n",
    "\t\tA = (self.X @ self.X.T / self.noise**2\n",
    "\t   \t\t + np.linalg.inv(self.prior_covar))\n",
    "\t\tself.posterior_covar = np.linalg.inv(A)\n",
    "\t\t# print(self.posterior_covar.shape)\n",
    "\t\t# print(\"X \", self.X.shape)\n",
    "\t\t# print(\"y \", self.y.shape)\n",
    "\t\t# print(\"prior covar \", self.prior_covar.shape)\n",
    "\t\t# print(\"prior mean \", self.prior_mean.shape)\n",
    "\t\tself.posterior_mean = (self.posterior_covar\n",
    "\t\t\t\t\t\t \t   @ (self.X @ self.y / self.noise**2\n",
    "\t\t\t  \t\t\t\t\t  + np.linalg.inv(self.prior_covar)\n",
    "\t\t\t\t\t\t\t\t  @ self.prior_mean))\n",
    "\n",
    "\t\t# print(\"post mean \", self.posterior_mean.shape)\n",
    "\t\t# print(\"post covar \", self.posterior_covar.shape)\n",
    "\t\treturn self.posterior_mean, self.posterior_covar\n",
    "\t\n",
    "\t# Compute mean and covariance of predictive distribution\n",
    "\tdef predict(self, test_input):\n",
    "\t\ttest_input = np.array(test_input)\n",
    "\t\tself.pred_mean = test_input.T @ self.posterior_mean\n",
    "\t\tself.pred_covar = test_input.T @ self.posterior_covar @ test_input\n",
    "\t\treturn self.pred_mean, self.pred_covar\n",
    "\n",
    "\n",
    "### Generate example linear dataset\n",
    "\n",
    "# Parameters for the linear relationship\n",
    "a = 2  # slope\n",
    "b = 3  # intercept\n",
    "c = 1\n",
    "noise_std = 30 # standard deviation of the noise\n",
    "\n",
    "np.random.seed(0)  # for reproducibility\n",
    "X = np.linspace(-5, 5, 100)\n",
    "\n",
    "# Generating Y values with noise\n",
    "y = a * X**2 + b * X + c\n",
    "y_noisy = y + np.random.normal(0, noise_std, y.shape)\n",
    "\n",
    "# Creating a DataFrame\n",
    "dataset = pd.DataFrame({'X': X, 'y': y})\n",
    "\n",
    "X_homo = X.reshape((1, -1))\n",
    "X_homo = np.vstack((X_homo, np.ones(X_homo.shape)))\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "print(X.shape)\n",
    "X_poly = poly.fit_transform(X.reshape(-1, 1))\n",
    "print(X_poly.shape)\n",
    "print(X_poly[1,:])\n",
    "print(y.shape)\n",
    "model = BayesRegression(X_poly.T, y_noisy, noise_std)\n",
    "model.set_prior(np.array([1, 3, 2]), 0.0001)\n",
    "post_mean, post_covar = model.fit()\n",
    "print(post_mean)\n",
    "print(post_covar)\n",
    "\n",
    "# Test inputs\n",
    "test_input = np.arange(-5, 5, 1).reshape(-1, 1)\n",
    "test_input_poly = poly.transform(test_input)\n",
    "# print(test_input_poly.shape)\n",
    "# test_input_homo = np.vstack((test_input, np.ones(test_input.shape)))\n",
    "pred_mean, pred_covar = model.predict(test_input_poly.T)\n",
    "print(pred_mean)\n",
    "print(pred_covar.shape)\n",
    "\n",
    "# print(X.shape, y.shape, y_noisy.shape)\n",
    "plt.scatter(X, y_noisy, marker='x')\n",
    "plt.plot(X, y, linestyle='--', color='black')\n",
    "plt.scatter(test_input, pred_mean, color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
